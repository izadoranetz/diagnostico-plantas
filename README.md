# DiagnÃ³stico de DoenÃ§as em Plantas

AplicaÃ§Ã£o Streamlit para detecÃ§Ã£o de anomalias em plantas usando aprendizado profundo, baseada no mÃ©todo proposto por **Katafuchi e Tokunaga (2020)** no artigo "Image-based Plant Disease Diagnosis with Unsupervised Anomaly Detection".

**ğŸ†• Sistema refatorado para seguir exatamente a implementaÃ§Ã£o do notebook `diagnostico_plantas.ipynb`**

> ğŸ““ **Notebook de ReferÃªncia**: O notebook original com o treinamento e implementaÃ§Ã£o completa estÃ¡ disponÃ­vel no Google Colab:
> [https://colab.research.google.com/drive/1jvj0GIocm_QFgZN2_-LFkDvV9XJLQuNX](https://colab.research.google.com/drive/1jvj0GIocm_QFgZN2_-LFkDvV9XJLQuNX)

## ğŸ“‹ Sobre

Esta aplicaÃ§Ã£o utiliza um modelo **Pix2Pix U-Net** para reconstruÃ§Ã£o de cor de imagens de plantas em escala de cinza. Ao comparar a imagem original com a reconstruÃ­da, o sistema detecta anomalias (possÃ­veis doenÃ§as) atravÃ©s de anÃ¡lises de diferenÃ§a de cor usando:

- **CIEDE2000**: MÃ©trica de diferenÃ§a de cor perceptual no espaÃ§o LAB
- **HSL Error**: AnÃ¡lise de erro no espaÃ§o de cor HSV (Hue, Saturation, Value)
- **Grad-CAM**: VisualizaÃ§Ã£o das regiÃµes de atenÃ§Ã£o do modelo durante a reconstruÃ§Ã£o
- **MÃ©tricas de localizaÃ§Ã£o**: Top 2% Mean Î”E e Top 1% Energy para quantificar anomalias

## ğŸ—ï¸ Arquitetura

O sistema utiliza uma **U-Net Generator** com:
- **Entrada**: Imagem em escala de cinza (1 canal, 256x256)
- **SaÃ­da**: Imagem RGB reconstruÃ­da (3 canais, 256x256)
- **Encoder**: 8 camadas de downsampling (64â†’128â†’256â†’512Ã—5)
- **Decoder**: 7 camadas de upsampling com skip connections + camada final
- **Dropout**: 0.5 nas primeiras 3 camadas do decoder
- **AtivaÃ§Ã£o**: Tanh na saÃ­da ([-1, 1])

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone <url-do-repositorio>
cd diagnostico-plantas
```

### 2. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 3. Configure o modelo

A aplicaÃ§Ã£o procura automaticamente por modelos treinados em:

1. **PrioritÃ¡rio**: `weights/modelo_final.pth` (modelo do notebook)

Certifique-se de ter pelo menos um desses arquivos no diretÃ³rio `weights/`.

### 4. Estrutura do projeto

```
diagnostico-plantas/
â”œâ”€â”€ app.py                    # AplicaÃ§Ã£o Streamlit principal
â”œâ”€â”€ model_loader.py           # Carregamento do modelo U-Net
â”œâ”€â”€ inference.py              # Pipeline de inferÃªncia
â”œâ”€â”€ gradcam.py                # Grad-CAM para explicabilidade
â”œâ”€â”€ metrics.py                # CÃ¡lculo de mÃ©tricas CIEDE2000 e HSL
â”œâ”€â”€ diagnosis.py              # LÃ³gica de diagnÃ³stico (threshold)
â”œâ”€â”€ requirements.txt          # DependÃªncias Python
â”œâ”€â”€ weights/                  # Modelos treinados
â”‚   â”œâ”€â”€ modelo_final.pth      # Modelo do notebook (prioritÃ¡rio)
â”‚   â””â”€â”€ latest_net_G.pth      # Modelo legacy (fallback)
â”œâ”€â”€ notebook/                 # Notebook de referÃªncia
â”‚   â””â”€â”€ diagnostico_plantas.ipynb
â”œâ”€â”€ data/                     # Dados de teste
â”œâ”€â”€ REFACTORING_SUMMARY.md    # DocumentaÃ§Ã£o da refatoraÃ§Ã£o
â”œâ”€â”€ COMPARISON.md             # Antes vs Depois
â””â”€â”€ README.md
```

## ğŸ’» Uso

### Executar a aplicaÃ§Ã£o

```bash
streamlit run app.py
```

A aplicaÃ§Ã£o serÃ¡ aberta automaticamente no navegador em `http://localhost:8501`.

### Funcionalidades

1. **Upload de Imagem**: FaÃ§a upload de uma imagem de folha (JPG, PNG)
2. **AnÃ¡lise AutomÃ¡tica**: A aplicaÃ§Ã£o irÃ¡:
   - Converter a imagem RGB para escala de cinza (1 canal)
   - Reconstruir as cores usando o modelo U-Net
   - Calcular mÃ©tricas de anomalia (CIEDE2000, HSL Error)
   - Gerar visualizaÃ§Ã£o Grad-CAM da atenÃ§Ã£o do modelo
3. **VisualizaÃ§Ãµes**: Veja 5 painÃ©is:
   - **Painel 1**: Entrada em escala de cinza
   - **Painel 2**: Imagem original RGB
   - **Painel 3**: Imagem reconstruÃ­da pelo modelo
   - **Painel 4**: Mapa de erro CIEDE2000 (hot colormap)
   - **Painel 5**: Grad-CAM - atenÃ§Ã£o do modelo durante reconstruÃ§Ã£o

### Pipeline Completo

```python
from inference import create_inference_engine
from gradcam import GradCAM
from metrics import calculate_all_metrics

# 1. Carregar modelo
model = create_inference_engine('weights/modelo_final.pth')

# 2. Inferir
original, gray, reconstructed, input_tensor = model.reconstruct(image)

# 3. Calcular mÃ©tricas
mask = leaf_mask_from_rgb(original)
de_map = de2000_map(original, reconstructed)
metrics = calculate_all_metrics(original, reconstructed, mask)

# 4. Gerar Grad-CAM
gradcam = GradCAM(model.model)
heatmap = gradcam.generate_heatmap(input_tensor)
```

## ğŸ“Š MÃ©tricas Utilizadas

### 1. CIEDE2000 Sum
Soma total da diferenÃ§a de cor CIEDE2000 na mÃ¡scara da folha. MÃ©trica perceptual que considera diferenÃ§as de cor como humanos as percebem. Valores altos indicam maior diferenÃ§a entre original e reconstruÃ­da.

**Limiar do notebook**: 136759 (score acima indica folha doente)

### 2. Top 2% Mean Î”E2000
MÃ©dia dos top 2% maiores erros de cor. Ãštil para detecÃ§Ã£o de anomalias concentradas em regiÃµes especÃ­ficas da folha.

### 3. Top 1% Energy Fraction
FraÃ§Ã£o de energia concentrada nos top 1% erros. Proxy para localizaÃ§Ã£o da anomalia - valores altos indicam anomalias bem localizadas.

### 4. HSL Error
Erro ponderado no espaÃ§o de cor HSV:
- **50% Hue (H)**: MudanÃ§a de cor (verde â†’ amarelo/marrom = doenÃ§a)
- **35% Saturation (S)**: Perda de saturaÃ§Ã£o (planta murcha)
- **15% Value (V)**: Escurecimento (necrose)

### 5. Grad-CAM
VisualizaÃ§Ã£o das regiÃµes onde o modelo concentrou sua atenÃ§Ã£o durante a reconstruÃ§Ã£o. Usa mapa de calor (heatmap), as Ã¡reas vermelhas indicam alta ativaÃ§Ã£o do modelo.

## ğŸ§ª Como Funciona

O algoritmo funciona em quatro etapas principais:

1. **ConversÃ£o para Grayscale**: 
   - A imagem RGB Ã© convertida para escala de cinza (1 canal)
   - Normalizada para [-1, 1] como no treinamento

2. **ReconstruÃ§Ã£o de Cor**: 
   - O modelo U-Net (treinado em plantas saudÃ¡veis) reconstrÃ³i as cores RGB
   - Plantas saudÃ¡veis terÃ£o reconstruÃ§Ã£o similar Ã  original
   - Plantas doentes terÃ£o diferenÃ§as significativas devido Ã s cores anÃ´malas

3. **AnÃ¡lise de DiferenÃ§a**:
   - ComparaÃ§Ã£o pixel a pixel entre original e reconstruÃ­da no espaÃ§o LAB
   - CÃ¡lculo de CIEDE2000 (mÃ©trica perceptual de diferenÃ§a de cor)
   - GeraÃ§Ã£o de mapas de erro e mÃ©tricas quantitativas

4. **Explicabilidade com Grad-CAM**:
   - Captura das ativaÃ§Ãµes e gradientes da Ãºltima camada convolucional
   - GeraÃ§Ã£o de mapa de calor mostrando regiÃµes de atenÃ§Ã£o do modelo
   - Overlay na imagem original para interpretaÃ§Ã£o visual

## ğŸ”§ Detalhes TÃ©cnicos

### Modelo U-Net
- **Entrada**: [1, 1, 256, 256] - Grayscale
- **SaÃ­da**: [1, 3, 256, 256] - RGB
- **Arquitetura**: 8 layers down + 7 layers up + final
- **NormalizaÃ§Ã£o**: BatchNorm em todas camadas exceto down1 e down8
- **Dropout**: 0.5 nas primeiras 3 camadas up (up1, up2, up3)
- **AtivaÃ§Ã£o final**: Tanh (saÃ­da em [-1, 1])

### Preprocessing
```python
# ConversÃ£o para grayscale
img_gray = img_rgb.convert("L")  # PIL Image (H, W)

# NormalizaÃ§Ã£o
tensor = (img_gray / 255.0) * 2.0 - 1.0  # [-1, 1]
tensor = tensor.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]
```

### Grad-CAM Implementation
```python
class GradCAM:
    def generate_heatmap(self, input_tensor):
        # Forward pass + captura de ativaÃ§Ãµes
        output = model(input_tensor)
        
        # Backward pass + captura de gradientes
        target.backward()
        
        # Combinar: weights = GAP(gradients)
        weights = torch.mean(gradients, dim=[2, 3])
        heatmap = sum(weights * activations)
        
        return relu(normalize(heatmap))
```

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **REFACTORING_SUMMARY.md**: DocumentaÃ§Ã£o completa das mudanÃ§as realizadas
- **COMPARISON.md**: ComparaÃ§Ã£o visual Antes vs Depois da refatoraÃ§Ã£o
- **notebook/diagnostico_plantas.ipynb**: ImplementaÃ§Ã£o de referÃªncia original

## ğŸ“ ReferÃªncias

- Katafuchi, R., & Tokunaga, T. (2020). Image-based Plant Disease Diagnosis with Unsupervised Anomaly Detection. arXiv preprint arXiv:2011.14306.
- Isola, P., et al. (2017). Image-to-Image Translation with Conditional Adversarial Networks. CVPR.
- Selvaraju, R. R., et al. (2017). Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization. ICCV.

