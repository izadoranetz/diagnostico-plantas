{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm1tc58J-F7C"
      },
      "outputs": [],
      "source": [
        "# Instalar bibliotecas necess√°rias\n",
        "!pip install torch torchvision\n",
        "!pip install scikit-image\n",
        "!pip install matplotlib pillow numpy\n",
        "\n",
        "# Clonar o reposit√≥rio do pix2pix\n",
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
        "%cd pytorch-CycleGAN-and-pix2pix\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import color\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Verificar se GPU est√° dispon√≠vel\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Usando: {device}')"
      ],
      "metadata": {
        "id": "L76RKDmN-WQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verificar se a pasta existe\n",
        "caminho_base = '/content/drive/MyDrive/plant_disease'\n",
        "if os.path.exists(caminho_base):\n",
        "    print(\"‚úì Pasta plant_disease encontrada!\")\n",
        "else:\n",
        "    print(\"‚úó Pasta n√£o encontrada. Verifique o nome e localiza√ß√£o.\")"
      ],
      "metadata": {
        "id": "UyMD4fjI-eVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def verificar_dataset(caminho_base):\n",
        "    \"\"\"\n",
        "    Verifica e exibe a estrutura do dataset.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ESTRUTURA DO DATASET\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar pasta de treino\n",
        "    train_path = Path(caminho_base) / 'train'\n",
        "    train_images = list(train_path.glob('*.jpg')) + list(train_path.glob('*.png')) + list(train_path.glob('*.jpeg'))\n",
        "    print(f\"\\nüìÅ TREINO (apenas plantas saud√°veis):\")\n",
        "    print(f\"   Localiza√ß√£o: {train_path}\")\n",
        "    print(f\"   Imagens: {len(train_images)}\")\n",
        "\n",
        "    # Verificar pasta de teste - saud√°veis\n",
        "    test_healthy_path = Path(caminho_base) / 'test' / 'healthy'\n",
        "    test_healthy_images = list(test_healthy_path.glob('*.jpg')) + list(test_healthy_path.glob('*.png')) + list(test_healthy_path.glob('*.jpeg'))\n",
        "    print(f\"\\nüìÅ TESTE - SAUD√ÅVEIS:\")\n",
        "    print(f\"   Localiza√ß√£o: {test_healthy_path}\")\n",
        "    print(f\"   Imagens: {len(test_healthy_images)}\")\n",
        "\n",
        "    # Verificar pasta de teste - doentes\n",
        "    test_diseased_path = Path(caminho_base) / 'test' / 'diseased'\n",
        "    test_diseased_images = list(test_diseased_path.glob('*.jpg')) + list(test_diseased_path.glob('*.png')) + list(test_diseased_path.glob('*.jpeg'))\n",
        "    print(f\"\\nüìÅ TESTE - DOENTES:\")\n",
        "    print(f\"   Localiza√ß√£o: {test_diseased_path}\")\n",
        "    print(f\"   Imagens: {len(test_diseased_images)}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"‚úì Total de imagens: {len(train_images) + len(test_healthy_images) + len(test_diseased_images)}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Mostrar algumas imagens de exemplo\n",
        "    if train_images:\n",
        "        print(f\"\\nExemplo de arquivos de treino:\")\n",
        "        for img in train_images[:3]:\n",
        "            print(f\"   ‚Ä¢ {img.name}\")\n",
        "\n",
        "    return {\n",
        "        'train': train_images,\n",
        "        'test_healthy': test_healthy_images,\n",
        "        'test_diseased': test_diseased_images\n",
        "    }\n",
        "\n",
        "# Verificar seus dados\n",
        "dados = verificar_dataset('/content/drive/MyDrive/plant_disease')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hwg4MJqT-lUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PlantDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset que carrega imagens de plantas e cria pares (escala de cinza, colorida).\n",
        "    \"\"\"\n",
        "    def __init__(self, lista_imagens, tamanho_imagem=256):\n",
        "        self.imagens = lista_imagens\n",
        "        self.tamanho = tamanho_imagem\n",
        "\n",
        "        # Transforma√ß√µes para redimensionar e normalizar\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((tamanho_imagem, tamanho_imagem)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        self.transform_gray = transforms.Compose([\n",
        "            transforms.Resize((tamanho_imagem, tamanho_imagem)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imagens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Carregar imagem colorida\n",
        "        img_path = self.imagens[idx]\n",
        "        img_color = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Converter para escala de cinza\n",
        "        img_gray = img_color.convert('L')\n",
        "\n",
        "        # Aplicar transforma√ß√µes\n",
        "        img_color_tensor = self.transform(img_color)\n",
        "        img_gray_tensor = self.transform_gray(img_gray)\n",
        "\n",
        "        return img_gray_tensor, img_color_tensor\n",
        "\n",
        "# Criar DataLoaders usando suas imagens\n",
        "train_dataset = PlantDataset(dados['train'])\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "print(f\"‚úì Dataset de treino criado: {len(train_dataset)} imagens\")\n",
        "print(f\"‚úì DataLoader configurado com batch_size=4\")"
      ],
      "metadata": {
        "id": "fhVYS5mn-vHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualizar_amostras(dataset, num_amostras=3):\n",
        "    \"\"\"\n",
        "    Visualiza algumas amostras do dataset.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(num_amostras, 2, figsize=(10, 4*num_amostras))\n",
        "\n",
        "    for i in range(num_amostras):\n",
        "        img_gray, img_color = dataset[i]\n",
        "\n",
        "        # Desnormalizar\n",
        "        img_gray_display = (img_gray.squeeze().numpy() + 1) / 2\n",
        "        img_color_display = (img_color.numpy().transpose(1, 2, 0) + 1) / 2\n",
        "        img_color_display = np.clip(img_color_display, 0, 1)\n",
        "\n",
        "        # Plotar\n",
        "        axes[i, 0].imshow(img_gray_display, cmap='gray')\n",
        "        axes[i, 0].set_title('Escala de Cinza (Entrada)', fontsize=12)\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        axes[i, 1].imshow(img_color_display)\n",
        "        axes[i, 1].set_title('Colorida (Alvo)', fontsize=12)\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "    plt.suptitle('Amostras do Dataset de Treino', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualizar suas imagens\n",
        "visualizar_amostras(train_dataset)"
      ],
      "metadata": {
        "id": "wkl3xvlB-zkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos implementar o pix2pix diretamente no Colab\n",
        "# para ter mais controle sobre o treinamento\n",
        "\n",
        "class UNetDown(nn.Module):\n",
        "    \"\"\"Bloco de downsampling do U-Net\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, normalize=True, dropout=0.0):\n",
        "        super(UNetDown, self).__init__()\n",
        "        layers = [nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False)]\n",
        "        if normalize:\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "        layers.append(nn.LeakyReLU(0.2))\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class UNetUp(nn.Module):\n",
        "    \"\"\"Bloco de upsampling do U-Net\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.0):\n",
        "        super(UNetUp, self).__init__()\n",
        "        layers = [\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        ]\n",
        "        if dropout:\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, skip_input):\n",
        "        x = self.model(x)\n",
        "        x = torch.cat((x, skip_input), 1)\n",
        "        return x\n",
        "\n",
        "class GeneratorUNet(nn.Module):\n",
        "    \"\"\"Gerador U-Net para pix2pix\"\"\"\n",
        "    def __init__(self, in_channels=1, out_channels=3):\n",
        "        super(GeneratorUNet, self).__init__()\n",
        "\n",
        "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
        "        self.down2 = UNetDown(64, 128)\n",
        "        self.down3 = UNetDown(128, 256)\n",
        "        self.down4 = UNetDown(256, 512, dropout=0.5)\n",
        "        self.down5 = UNetDown(512, 512, dropout=0.5)\n",
        "        self.down6 = UNetDown(512, 512, dropout=0.5)\n",
        "        self.down7 = UNetDown(512, 512, dropout=0.5)\n",
        "        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)\n",
        "\n",
        "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
        "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
        "        self.up3 = UNetUp(1024, 512, dropout=0.5)\n",
        "        self.up4 = UNetUp(1024, 512, dropout=0.5)\n",
        "        self.up5 = UNetUp(1024, 256)\n",
        "        self.up6 = UNetUp(512, 128)\n",
        "        self.up7 = UNetUp(256, 64)\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, out_channels, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder (downsampling)\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(d1)\n",
        "        d3 = self.down3(d2)\n",
        "        d4 = self.down4(d3)\n",
        "        d5 = self.down5(d4)\n",
        "        d6 = self.down6(d5)\n",
        "        d7 = self.down7(d6)\n",
        "        d8 = self.down8(d7)\n",
        "\n",
        "        # Decoder (upsampling) com skip connections\n",
        "        u1 = self.up1(d8, d7)\n",
        "        u2 = self.up2(u1, d6)\n",
        "        u3 = self.up3(u2, d5)\n",
        "        u4 = self.up4(u3, d4)\n",
        "        u5 = self.up5(u4, d3)\n",
        "        u6 = self.up6(u5, d2)\n",
        "        u7 = self.up7(u6, d1)\n",
        "\n",
        "        return self.final(u7)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Discriminador PatchGAN para pix2pix\"\"\"\n",
        "    def __init__(self, in_channels=4):  # 1 (gray) + 3 (RGB)\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, 2, 1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(in_channels, 64, normalize=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img_gray, img_color):\n",
        "        img_input = torch.cat((img_gray, img_color), 1)\n",
        "        return self.model(img_input)\n",
        "\n",
        "# Inicializar modelos\n",
        "gerador = GeneratorUNet(in_channels=1, out_channels=3).to(device)\n",
        "discriminador = Discriminator(in_channels=4).to(device)\n",
        "\n",
        "print(\"‚úì Gerador criado (U-Net com skip connections)\")\n",
        "print(\"‚úì Discriminador criado (PatchGAN)\")"
      ],
      "metadata": {
        "id": "LR5ebQhm-5UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "# Otimizadores (conforme o artigo)\n",
        "optimizer_G = Adam(gerador.parameters(), lr=0.000015, betas=(0.9, 0.999))\n",
        "optimizer_D = Adam(discriminador.parameters(), lr=0.000015, betas=(0.9, 0.999))\n",
        "\n",
        "# Fun√ß√µes de perda\n",
        "criterion_GAN = nn.BCEWithLogitsLoss()\n",
        "criterion_L1 = nn.L1Loss()\n",
        "\n",
        "# Peso para regulariza√ß√£o L1 (conforme o artigo)\n",
        "lambda_L1 = 1\n",
        "\n",
        "print(\"‚úì Otimizadores configurados (Adam, lr=0.00015)\")\n",
        "print(\"‚úì Fun√ß√µes de perda: BCE + L1\")"
      ],
      "metadata": {
        "id": "UoP0xuys--Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def treinar_pix2pix(gerador, discriminador, train_loader, num_epochs=150):\n",
        "    \"\"\"\n",
        "    Treina o modelo pix2pix.\n",
        "\n",
        "    Args:\n",
        "        gerador: Modelo gerador (U-Net)\n",
        "        discriminador: Modelo discriminador (PatchGAN)\n",
        "        train_loader: DataLoader com dados de treino\n",
        "        num_epochs: N√∫mero de √©pocas (padr√£o: 150 conforme artigo)\n",
        "    \"\"\"\n",
        "    historico = {\n",
        "        'loss_G': [],\n",
        "        'loss_D': [],\n",
        "        'loss_L1': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        gerador.train()\n",
        "        discriminador.train()\n",
        "\n",
        "        epoch_loss_G = 0\n",
        "        epoch_loss_D = 0\n",
        "        epoch_loss_L1 = 0\n",
        "\n",
        "        # Barra de progresso\n",
        "        pbar = tqdm(train_loader, desc=f'√âpoca {epoch+1}/{num_epochs}')\n",
        "\n",
        "        for i, (img_gray, img_color) in enumerate(pbar):\n",
        "            img_gray = img_gray.to(device)\n",
        "            img_color = img_color.to(device)\n",
        "\n",
        "            batch_size = img_gray.size(0)\n",
        "\n",
        "            # Labels para adversarial loss\n",
        "            real_label = torch.ones(batch_size, 1, 16, 16).to(device)\n",
        "            fake_label = torch.zeros(batch_size, 1, 16, 16).to(device)\n",
        "\n",
        "            # ---------------------\n",
        "            #  Treinar Gerador\n",
        "            # ---------------------\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # Gerar imagens falsas\n",
        "            fake_color = gerador(img_gray)\n",
        "\n",
        "            # Adversarial loss\n",
        "            pred_fake = discriminador(img_gray, fake_color)\n",
        "            loss_GAN = criterion_GAN(pred_fake, real_label)\n",
        "\n",
        "            # L1 loss\n",
        "            loss_L1 = criterion_L1(fake_color, img_color)\n",
        "\n",
        "            # Loss total do gerador\n",
        "            loss_G = loss_GAN + lambda_L1 * loss_L1\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # ---------------------\n",
        "            #  Treinar Discriminador\n",
        "            # ---------------------\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Loss com imagens reais\n",
        "            pred_real = discriminador(img_gray, img_color)\n",
        "            loss_real = criterion_GAN(pred_real, real_label)\n",
        "\n",
        "            # Loss com imagens falsas\n",
        "            pred_fake = discriminador(img_gray, fake_color.detach())\n",
        "            loss_fake = criterion_GAN(pred_fake, fake_label)\n",
        "\n",
        "            # Loss total do discriminador\n",
        "            loss_D = (loss_real + loss_fake) * 0.5\n",
        "            loss_D.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Acumular losses\n",
        "            epoch_loss_G += loss_G.item()\n",
        "            epoch_loss_D += loss_D.item()\n",
        "            epoch_loss_L1 += loss_L1.item()\n",
        "\n",
        "            # Atualizar barra de progresso\n",
        "            pbar.set_postfix({\n",
        "                'G': f'{loss_G.item():.4f}',\n",
        "                'D': f'{loss_D.item():.4f}',\n",
        "                'L1': f'{loss_L1.item():.4f}'\n",
        "            })\n",
        "\n",
        "        # M√©dias da √©poca\n",
        "        avg_loss_G = epoch_loss_G / len(train_loader)\n",
        "        avg_loss_D = epoch_loss_D / len(train_loader)\n",
        "        avg_loss_L1 = epoch_loss_L1 / len(train_loader)\n",
        "\n",
        "        historico['loss_G'].append(avg_loss_G)\n",
        "        historico['loss_D'].append(avg_loss_D)\n",
        "        historico['loss_L1'].append(avg_loss_L1)\n",
        "\n",
        "        print(f'\\n√âpoca {epoch+1}/{num_epochs}:')\n",
        "        print(f'  Loss Gerador: {avg_loss_G:.4f}')\n",
        "        print(f'  Loss Discriminador: {avg_loss_D:.4f}')\n",
        "        print(f'  Loss L1: {avg_loss_L1:.4f}\\n')\n",
        "\n",
        "        # Salvar checkpoint a cada 10 √©pocas\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            checkpoint_path = f'/content/drive/MyDrive/plant_disease/checkpoint_epoch_{epoch+1}.pth'\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'gerador_state_dict': gerador.state_dict(),\n",
        "                'discriminador_state_dict': discriminador.state_dict(),\n",
        "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
        "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
        "            }, checkpoint_path)\n",
        "            print(f'‚úì Checkpoint salvo: {checkpoint_path}')\n",
        "\n",
        "    # Salvar modelo final\n",
        "    modelo_final = '/content/drive/MyDrive/plant_disease/modelo_final.pth'\n",
        "    torch.save(gerador.state_dict(), modelo_final)\n",
        "    print(f'\\n‚úì Modelo final salvo: {modelo_final}')\n",
        "\n",
        "    return historico\n",
        "\n",
        "# INICIAR TREINAMENTO\n",
        "print(\"üöÄ Iniciando treinamento...\")\n",
        "print(f\"   √âpocas: 150\")\n",
        "print(f\"   Batch size: 4\")\n",
        "print(f\"   Imagens de treino: {len(train_dataset)}\")\n",
        "print(f\"   Device: {device}\\n\")\n",
        "\n",
        "historico = treinar_pix2pix(gerador, discriminador, train_loader, num_epochs=150)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "juy1nPH6_Bhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotar_historico(historico):\n",
        "    \"\"\"\n",
        "    Plota as curvas de loss durante o treinamento.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    epochs = range(1, len(historico['loss_G']) + 1)\n",
        "\n",
        "    # Loss Gerador e Discriminador\n",
        "    axes[0].plot(epochs, historico['loss_G'], label='Gerador', color='blue', linewidth=2)\n",
        "    axes[0].plot(epochs, historico['loss_D'], label='Discriminador', color='red', linewidth=2)\n",
        "    axes[0].set_xlabel('√âpoca', fontsize=12)\n",
        "    axes[0].set_ylabel('Loss', fontsize=12)\n",
        "    axes[0].set_title('Loss Adversarial', fontsize=14, fontweight='bold')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Loss L1\n",
        "    axes[1].plot(epochs, historico['loss_L1'], label='L1 Loss', color='green', linewidth=2)\n",
        "    axes[1].set_xlabel('√âpoca', fontsize=12)\n",
        "    axes[1].set_ylabel('Loss L1', fontsize=12)\n",
        "    axes[1].set_title('Loss de Reconstru√ß√£o (L1)', fontsize=14, fontweight='bold')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/plant_disease/historico_treinamento.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"‚úì Gr√°fico salvo no Drive\")\n",
        "\n",
        "plotar_historico(historico)"
      ],
      "metadata": {
        "id": "yUglfPv_BByf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def carregar_modelo_treinado(caminho_modelo):\n",
        "    \"\"\"\n",
        "    Carrega o modelo treinado do Google Drive.\n",
        "\n",
        "    Args:\n",
        "        caminho_modelo: Caminho para o arquivo .pth\n",
        "\n",
        "    Returns:\n",
        "        Gerador carregado em modo de avalia√ß√£o\n",
        "    \"\"\"\n",
        "    gerador = GeneratorUNet(in_channels=1, out_channels=3).to(device)\n",
        "    gerador.load_state_dict(torch.load(caminho_modelo, map_location=device))\n",
        "    gerador.eval()\n",
        "\n",
        "    print(\"‚úì Modelo carregado com sucesso!\")\n",
        "    return gerador\n",
        "\n",
        "# Para usar depois (ap√≥s treinar):\n",
        "gerador = carregar_modelo_treinado('/content/drive/MyDrive/plant_disease/modelo_final.pth')"
      ],
      "metadata": {
        "id": "LQd3Vs7UBP6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import rgb2lab, deltaE_ciede2000\n",
        "\n",
        "def calcular_ciede2000(img_original, img_reconstruida):\n",
        "    \"\"\"\n",
        "    Calcula a diferen√ßa de cor CIEDE2000 entre duas imagens.\n",
        "\n",
        "    Esta m√©trica reflete como humanos percebem diferen√ßas de cor.\n",
        "\n",
        "    Args:\n",
        "        img_original: Imagem RGB original (numpy array)\n",
        "        img_reconstruida: Imagem RGB reconstru√≠da (numpy array)\n",
        "\n",
        "    Returns:\n",
        "        mapa_diferenca: Mapa de calor com diferen√ßas por pixel\n",
        "        score_total: Score de anomalia (soma das diferen√ßas)\n",
        "    \"\"\"\n",
        "    # Converter RGB para espa√ßo de cor LAB\n",
        "    # LAB √© melhor para comparar cores como humanos veem\n",
        "    lab_original = rgb2lab(img_original)\n",
        "    lab_reconstruida = rgb2lab(img_reconstruida)\n",
        "\n",
        "    # Calcular diferen√ßa CIEDE2000 para cada pixel\n",
        "    mapa_diferenca = deltaE_ciede2000(lab_original, lab_reconstruida)\n",
        "\n",
        "    # Score total = soma de todas as diferen√ßas\n",
        "    score_total = np.sum(mapa_diferenca)\n",
        "\n",
        "    return mapa_diferenca, score_total"
      ],
      "metadata": {
        "id": "exV9nPMpBWGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnosticar_folha(caminho_imagem, gerador, limiar):\n",
        "    \"\"\"\n",
        "    Diagnostica se uma folha est√° saud√°vel ou doente.\n",
        "\n",
        "    Args:\n",
        "        caminho_imagem: Caminho para a imagem da folha\n",
        "        gerador: Modelo treinado\n",
        "        limiar: Valor acima do qual a folha √© considerada doente\n",
        "\n",
        "    Returns:\n",
        "        dict com diagn√≥stico completo\n",
        "    \"\"\"\n",
        "    # 1. Carregar e preparar imagem\n",
        "    img_original = Image.open(caminho_imagem).convert('RGB')\n",
        "    img_original = img_original.resize((256, 256))\n",
        "    img_array = np.array(img_original) / 255.0\n",
        "\n",
        "    # 2. Converter para escala de cinza e normalizar\n",
        "    img_gray = img_original.convert('L')\n",
        "\n",
        "    transform_gray = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    img_gray_tensor = transform_gray(img_gray).unsqueeze(0).to(device)\n",
        "\n",
        "    # 3. Reconstruir cores usando o modelo\n",
        "    gerador.eval()\n",
        "    with torch.no_grad():\n",
        "        img_reconstruida_tensor = gerador(img_gray_tensor)\n",
        "\n",
        "    # 4. Converter de volta para numpy\n",
        "    img_reconstruida = img_reconstruida_tensor.squeeze().cpu().numpy()\n",
        "    img_reconstruida = np.transpose(img_reconstruida, (1, 2, 0))\n",
        "    img_reconstruida = (img_reconstruida + 1) / 2  # Desnormalizar [-1,1] -> [0,1]\n",
        "    img_reconstruida = np.clip(img_reconstruida, 0, 1)\n",
        "\n",
        "    # 5. Calcular diferen√ßa de cor\n",
        "    mapa_diferenca, score = calcular_ciede2000(img_array, img_reconstruida)\n",
        "\n",
        "    # 6. Determinar diagn√≥stico\n",
        "    diagnostico = \"DOENTE\" if score > limiar else \"SAUD√ÅVEL\"\n",
        "    confianca = min(100, (score / limiar) * 100) if diagnostico == \"DOENTE\" else max(0, 100 - (score / limiar) * 100)\n",
        "\n",
        "    return {\n",
        "        'diagnostico': diagnostico,\n",
        "        'score_anomalia': score,\n",
        "        'confianca': confianca,\n",
        "        'imagem_original': img_array,\n",
        "        'imagem_reconstruida': img_reconstruida,\n",
        "        'mapa_calor': mapa_diferenca,\n",
        "        'arquivo': Path(caminho_imagem).name\n",
        "    }"
      ],
      "metadata": {
        "id": "4TK5Bs_IBc_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_folha_saudavel(caminho_imagem, gerador):\n",
        "    \"\"\"\n",
        "    Gera uma vers√£o \"saud√°vel\" da folha reconstruindo suas cores.\n",
        "\n",
        "    Args:\n",
        "        caminho_imagem: Caminho para a imagem da folha\n",
        "        gerador: Modelo treinado\n",
        "\n",
        "    Returns:\n",
        "        Imagem numpy array da folha com cores reconstru√≠das\n",
        "    \"\"\"\n",
        "    # Carregar imagem\n",
        "    img_original = Image.open(caminho_imagem).convert('RGB')\n",
        "    img_original = img_original.resize((256, 256))\n",
        "\n",
        "    # Converter para escala de cinza e normalizar\n",
        "    img_gray = img_original.convert('L')\n",
        "\n",
        "    transform_gray = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    img_gray_tensor = transform_gray(img_gray).unsqueeze(0).to(device)\n",
        "\n",
        "    # Reconstruir cores\n",
        "    gerador.eval()\n",
        "    with torch.no_grad():\n",
        "        img_saudavel_tensor = gerador(img_gray_tensor)\n",
        "\n",
        "    # Converter para numpy\n",
        "    img_saudavel = img_saudavel_tensor.squeeze().cpu().numpy()\n",
        "    img_saudavel = np.transpose(img_saudavel, (1, 2, 0))\n",
        "    img_saudavel = (img_saudavel + 1) / 2\n",
        "    img_saudavel = np.clip(img_saudavel, 0, 1)\n",
        "\n",
        "    return img_saudavel"
      ],
      "metadata": {
        "id": "XLTtCuEVBeIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualizar_indice_cores(resultado_diagnostico, salvar=False, caminho_saida='resultado.png'):\n",
        "    \"\"\"\n",
        "    Cria visualiza√ß√£o completa com √≠ndice de cores para anomalias.\n",
        "\n",
        "    Args:\n",
        "        resultado_diagnostico: Dict retornado por diagnosticar_folha()\n",
        "        salvar: Se True, salva a figura\n",
        "        caminho_saida: Onde salvar a figura\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "    # 1. Imagem Original\n",
        "    axes[0, 0].imshow(resultado_diagnostico['imagem_original'])\n",
        "    axes[0, 0].set_title('Imagem Original', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    # 2. Imagem Reconstru√≠da (Folha \"Saud√°vel\")\n",
        "    axes[0, 1].imshow(resultado_diagnostico['imagem_reconstruida'])\n",
        "    axes[0, 1].set_title('Reconstru√ß√£o (Folha Saud√°vel)', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    # 3. Mapa de Calor de Anomalias\n",
        "    im = axes[1, 0].imshow(\n",
        "        resultado_diagnostico['mapa_calor'],\n",
        "        cmap='hot',  # Vermelho = mais an√¥malo\n",
        "        interpolation='bilinear'\n",
        "    )\n",
        "    axes[1, 0].set_title('Mapa de Anomalias (CIEDE2000)', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    # Adicionar barra de cores\n",
        "    cbar = plt.colorbar(im, ax=axes[1, 0], fraction=0.046, pad=0.04)\n",
        "    cbar.set_label('Diferen√ßa de Cor', rotation=270, labelpad=20)\n",
        "\n",
        "    # 4. Diagn√≥stico e Estat√≠sticas\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    # Criar texto do diagn√≥stico\n",
        "    diagnostico = resultado_diagnostico['diagnostico']\n",
        "    score = resultado_diagnostico['score_anomalia']\n",
        "    confianca = resultado_diagnostico['confianca']\n",
        "\n",
        "    cor_diagnostico = 'red' if diagnostico == \"DOENTE\" else 'green'\n",
        "\n",
        "    texto = f\"\"\"\n",
        "    DIAGN√ìSTICO: {diagnostico}\n",
        "\n",
        "    Score de Anomalia: {score:.0f}\n",
        "    Confian√ßa: {confianca:.1f}%\n",
        "\n",
        "    Interpreta√ß√£o:\n",
        "    ‚Ä¢ √Åreas vermelhas = Anomalias fortes\n",
        "    ‚Ä¢ √Åreas amarelas = Anomalias moderadas\n",
        "    ‚Ä¢ √Åreas escuras = Tecido saud√°vel\n",
        "\n",
        "    O modelo foi treinado apenas com\n",
        "    folhas saud√°veis. √Åreas doentes\n",
        "    aparecem em vermelho porque o\n",
        "    modelo n√£o consegue reconstruir\n",
        "    suas cores corretamente.\n",
        "    \"\"\"\n",
        "\n",
        "    axes[1, 1].text(\n",
        "        0.1, 0.5, texto,\n",
        "        fontsize=12,\n",
        "        verticalalignment='center',\n",
        "        bbox=dict(boxstyle='round', facecolor=cor_diagnostico, alpha=0.2)\n",
        "    )\n",
        "\n",
        "    plt.suptitle(\n",
        "        f'An√°lise Completa - {diagnostico}',\n",
        "        fontsize=16,\n",
        "        fontweight='bold',\n",
        "        color=cor_diagnostico\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if salvar:\n",
        "        plt.savefig(caminho_saida, dpi=300, bbox_inches='tight')\n",
        "        print(f\"‚úì Resultado salvo em: {caminho_saida}\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kT3s1K07Bh9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Certifique-se de que o modelo est√° carregado\n",
        "gerador = carregar_modelo_treinado('/content/drive/MyDrive/plant_disease/modelo_final.pth')\n",
        "\n",
        "# 1. Diagnosticar uma imagem de teste doente\n",
        "caminho_teste = '/content/drive/MyDrive/plant_disease/test/diseased/a976-979 ab_2.jpg'\n",
        "\n",
        "resultado = diagnosticar_folha(\n",
        "    caminho_imagem=caminho_teste,\n",
        "    gerador=gerador,\n",
        "    limiar=121462  # Ajuste este valor baseado nos seus dados\n",
        ")\n",
        "\n",
        "# 2. Visualizar resultado completo\n",
        "visualizar_indice_cores(resultado, salvar=True,\n",
        "                        caminho_saida='/content/drive/MyDrive/plant_disease/resultado_diagnostico.png')\n",
        "\n",
        "# 3. Imprimir resumo\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"ARQUIVO: {resultado['arquivo']}\")\n",
        "print(f\"DIAGN√ìSTICO: {resultado['diagnostico']}\")\n",
        "print(f\"Score de Anomalia: {resultado['score_anomalia']:.0f}\")\n",
        "print(f\"Confian√ßa: {resultado['confianca']:.1f}%\")\n",
        "print(f\"{'='*50}\\n\")"
      ],
      "metadata": {
        "id": "Tz7VJ8YkBk60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encontrar_limiar_otimo(gerador, pasta_saudaveis, pasta_doentes):\n",
        "    \"\"\"\n",
        "    Encontra o limiar ideal testando com imagens saud√°veis e doentes.\n",
        "\n",
        "    Args:\n",
        "        gerador: Modelo treinado\n",
        "        pasta_saudaveis: Caminho para pasta com imagens saud√°veis\n",
        "        pasta_doentes: Caminho para pasta com imagens doentes\n",
        "\n",
        "    Returns:\n",
        "        Limiar recomendado\n",
        "    \"\"\"\n",
        "    print(\"üîç Calculando scores para encontrar limiar ideal...\\n\")\n",
        "\n",
        "    # Calcular scores para imagens saud√°veis\n",
        "    scores_saudaveis = []\n",
        "    imgs_saudaveis = list(Path(pasta_saudaveis).glob('*.jpg')) + \\\n",
        "                     list(Path(pasta_saudaveis).glob('*.png'))\n",
        "\n",
        "    print(f\"Testando {len(imgs_saudaveis)} imagens saud√°veis...\")\n",
        "    for img_path in imgs_saudaveis[:20]:  # Testar primeiras 20\n",
        "        resultado = diagnosticar_folha(str(img_path), gerador, limiar=999999)\n",
        "        scores_saudaveis.append(resultado['score_anomalia'])\n",
        "\n",
        "    # Calcular scores para imagens doentes\n",
        "    scores_doentes = []\n",
        "    imgs_doentes = list(Path(pasta_doentes).glob('*.jpg')) + \\\n",
        "                   list(Path(pasta_doentes).glob('*.png'))\n",
        "\n",
        "    print(f\"Testando {len(imgs_doentes)} imagens doentes...\")\n",
        "    for img_path in imgs_doentes[:20]:  # Testar primeiras 20\n",
        "        resultado = diagnosticar_folha(str(img_path), gerador, limiar=999999)\n",
        "        scores_doentes.append(resultado['score_anomalia'])\n",
        "\n",
        "    # Calcular estat√≠sticas\n",
        "    media_saudavel = np.mean(scores_saudaveis)\n",
        "    std_saudavel = np.std(scores_saudaveis)\n",
        "    media_doente = np.mean(scores_doentes)\n",
        "    std_doente = np.std(scores_doentes)\n",
        "\n",
        "    # Limiar = ponto m√©dio entre as m√©dias\n",
        "    limiar_recomendado = (media_saudavel + media_doente) / 2\n",
        "\n",
        "    # Visualizar distribui√ß√µes\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(scores_saudaveis, bins=20, alpha=0.7, color='green', label='Saud√°veis')\n",
        "    plt.hist(scores_doentes, bins=20, alpha=0.7, color='red', label='Doentes')\n",
        "    plt.axvline(limiar_recomendado, color='blue', linestyle='--', linewidth=2, label=f'Limiar: {limiar_recomendado:.0f}')\n",
        "    plt.xlabel('Score de Anomalia')\n",
        "    plt.ylabel('Frequ√™ncia')\n",
        "    plt.title('Distribui√ß√£o dos Scores')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.boxplot([scores_saudaveis, scores_doentes], labels=['Saud√°veis', 'Doentes'])\n",
        "    plt.ylabel('Score de Anomalia')\n",
        "    plt.title('Compara√ß√£o dos Scores')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/plant_disease/analise_limiar.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ESTAT√çSTICAS:\")\n",
        "    print(f\"  Saud√°veis: m√©dia={media_saudavel:.0f}, std={std_saudavel:.0f}\")\n",
        "    print(f\"  Doentes:   m√©dia={media_doente:.0f}, std={std_doente:.0f}\")\n",
        "    print(f\"\\n‚úì LIMIAR RECOMENDADO: {limiar_recomendado:.0f}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return limiar_recomendado\n",
        "\n",
        "# Encontrar limiar ideal\n",
        "limiar_otimo = encontrar_limiar_otimo(\n",
        "    gerador,\n",
        "    pasta_saudaveis='/content/drive/MyDrive/plant_disease/test/healthy',\n",
        "    pasta_doentes='/content/drive/MyDrive/plant_disease/test/diseased'\n",
        ")"
      ],
      "metadata": {
        "id": "iNyIAeWzCZh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processar_lote_completo(gerador, dados, limiar):\n",
        "    \"\"\"\n",
        "    Processa todas as imagens de teste e gera relat√≥rio.\n",
        "\n",
        "    Args:\n",
        "        gerador: Modelo treinado\n",
        "        dados: Dict retornado pela fun√ß√£o verificar_dataset\n",
        "        limiar: Valor de limiar para classifica√ß√£o\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com resultados\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    resultados = []\n",
        "\n",
        "    # Criar pasta para salvar resultados\n",
        "    pasta_resultados = '/content/drive/MyDrive/plant_disease/resultados'\n",
        "    os.makedirs(pasta_resultados, exist_ok=True)\n",
        "    os.makedirs(f'{pasta_resultados}/healthy', exist_ok=True)\n",
        "    os.makedirs(f'{pasta_resultados}/diseased', exist_ok=True)\n",
        "\n",
        "    print(\"üî¨ PROCESSANDO IMAGENS DE TESTE\\n\")\n",
        "\n",
        "    # Processar imagens saud√°veis\n",
        "    print(\"üìó Processando folhas saud√°veis...\")\n",
        "    for img_path in tqdm(dados['test_healthy']):\n",
        "        resultado = diagnosticar_folha(str(img_path), gerador, limiar)\n",
        "\n",
        "        resultados.append({\n",
        "            'arquivo': resultado['arquivo'],\n",
        "            'tipo_real': 'SAUD√ÅVEL',\n",
        "            'diagnostico': resultado['diagnostico'],\n",
        "            'score': resultado['score_anomalia'],\n",
        "            'confianca': resultado['confianca'],\n",
        "            'correto': resultado['diagnostico'] == 'SAUD√ÅVEL'\n",
        "        })\n",
        "\n",
        "        # Salvar visualiza√ß√£o\n",
        "        visualizar_indice_cores(\n",
        "            resultado,\n",
        "            salvar=True,\n",
        "            caminho_saida=f\"{pasta_resultados}/healthy/{resultado['arquivo'].replace('.jpg', '_analise.png')}\"\n",
        "        )\n",
        "        plt.close()\n",
        "\n",
        "    # Processar imagens doentes\n",
        "    print(\"\\nüìï Processando folhas doentes...\")\n",
        "    for img_path in tqdm(dados['test_diseased']):\n",
        "        resultado = diagnosticar_folha(str(img_path), gerador, limiar)\n",
        "\n",
        "        resultados.append({\n",
        "            'arquivo': resultado['arquivo'],\n",
        "            'tipo_real': 'DOENTE',\n",
        "            'diagnostico': resultado['diagnostico'],\n",
        "            'score': resultado['score_anomalia'],\n",
        "            'confianca': resultado['confianca'],\n",
        "            'correto': resultado['diagnostico'] == 'DOENTE'\n",
        "        })\n",
        "\n",
        "        # Salvar visualiza√ß√£o\n",
        "        visualizar_indice_cores(\n",
        "            resultado,\n",
        "            salvar=True,\n",
        "            caminho_saida=f\"{pasta_resultados}/diseased/{resultado['arquivo'].replace('.jpg', '_analise.png')}\"\n",
        "        )\n",
        "        plt.close()\n",
        "\n",
        "    # Criar DataFrame\n",
        "    df = pd.DataFrame(resultados)\n",
        "\n",
        "    # Calcular m√©tricas\n",
        "    acuracia = (df['correto'].sum() / len(df)) * 100\n",
        "\n",
        "    precisao_doente = (df[(df['diagnostico'] == 'DOENTE') & (df['correto'] == True)].shape[0] /\n",
        "                       df[df['diagnostico'] == 'DOENTE'].shape[0] * 100) if df[df['diagnostico'] == 'DOENTE'].shape[0] > 0 else 0\n",
        "\n",
        "    recall_doente = (df[(df['tipo_real'] == 'DOENTE') & (df['correto'] == True)].shape[0] /\n",
        "                     df[df['tipo_real'] == 'DOENTE'].shape[0] * 100)\n",
        "\n",
        "    # Salvar CSV\n",
        "    df.to_csv(f'{pasta_resultados}/resultados_completos.csv', index=False)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"RESULTADOS FINAIS:\")\n",
        "    print(f\"  Total de imagens: {len(df)}\")\n",
        "    print(f\"  Acur√°cia: {acuracia:.2f}%\")\n",
        "    print(f\"  Precis√£o (doentes): {precisao_doente:.2f}%\")\n",
        "    print(f\"  Recall (doentes): {recall_doente:.2f}%\")\n",
        "    print(f\"\\n‚úì Resultados salvos em: {pasta_resultados}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Processar tudo\n",
        "df_resultados = processar_lote_completo(gerador, dados, limiar_otimo)\n",
        "\n",
        "# Visualizar matriz de confus√£o\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(df_resultados['tipo_real'], df_resultados['diagnostico'],\n",
        "                      labels=['SAUD√ÅVEL', 'DOENTE'])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['SAUD√ÅVEL', 'DOENTE'],\n",
        "            yticklabels=['SAUD√ÅVEL', 'DOENTE'])\n",
        "plt.ylabel('Tipo Real')\n",
        "plt.xlabel('Diagn√≥stico')\n",
        "plt.title('Matriz de Confus√£o', fontsize=14, fontweight='bold')\n",
        "plt.savefig('/content/drive/MyDrive/plant_disease/matriz_confusao.png', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i8AXaosgCdWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encontrar_limiar_otimo(gerador, pasta_saudaveis, pasta_doentes):\n",
        "    \"\"\"\n",
        "    Encontra o limiar ideal testando com imagens saud√°veis e doentes.\n",
        "\n",
        "    Args:\n",
        "        gerador: Modelo treinado\n",
        "        pasta_saudaveis: Caminho para pasta com imagens saud√°veis\n",
        "        pasta_doentes: Caminho para pasta com imagens doentes\n",
        "\n",
        "    Returns:\n",
        "        Limiar recomendado\n",
        "    \"\"\"\n",
        "    print(\"üîç Calculando scores para encontrar limiar ideal...\\n\")\n",
        "\n",
        "    # Calcular scores para imagens saud√°veis\n",
        "    scores_saudaveis = []\n",
        "    imgs_saudaveis = list(Path(pasta_saudaveis).glob('*.jpg')) + \\\n",
        "                     list(Path(pasta_saudaveis).glob('*.png'))\n",
        "\n",
        "    print(f\"Testando {len(imgs_saudaveis)} imagens saud√°veis...\")\n",
        "    for img_path in imgs_saudaveis[:50]:  # Testar primeiras 20\n",
        "        resultado = diagnosticar_folha(str(img_path), gerador, limiar=999999)\n",
        "        scores_saudaveis.append(resultado['score_anomalia'])\n",
        "\n",
        "    # Calcular scores para imagens doentes\n",
        "    scores_doentes = []\n",
        "    imgs_doentes = list(Path(pasta_doentes).glob('*.jpg')) + \\\n",
        "                   list(Path(pasta_doentes).glob('*.png'))\n",
        "\n",
        "    print(f\"Testando {len(imgs_doentes)} imagens doentes...\")\n",
        "    for img_path in imgs_doentes[:100]:  # Testar primeiras 20\n",
        "        resultado = diagnosticar_folha(str(img_path), gerador, limiar=999999)\n",
        "        scores_doentes.append(resultado['score_anomalia'])\n",
        "\n",
        "    # Calcular estat√≠sticas\n",
        "    media_saudavel = np.mean(scores_saudaveis)\n",
        "    std_saudavel = np.std(scores_saudaveis)\n",
        "    media_doente = np.mean(scores_doentes)\n",
        "    std_doente = np.std(scores_doentes)\n",
        "\n",
        "    # Limiar = ponto m√©dio entre as m√©dias\n",
        "    limiar_recomendado = (media_saudavel + media_doente) / 2\n",
        "\n",
        "    # Visualizar distribui√ß√µes\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(scores_saudaveis, bins=20, alpha=0.7, color='green', label='Saud√°veis')\n",
        "    plt.hist(scores_doentes, bins=20, alpha=0.7, color='red', label='Doentes')\n",
        "    plt.axvline(limiar_recomendado, color='blue', linestyle='--', linewidth=2, label=f'Limiar: {limiar_recomendado:.0f}')\n",
        "    plt.xlabel('Score de Anomalia')\n",
        "    plt.ylabel('Frequ√™ncia')\n",
        "    plt.title('Distribui√ß√£o dos Scores')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.boxplot([scores_saudaveis, scores_doentes], labels=['Saud√°veis', 'Doentes'])\n",
        "    plt.ylabel('Score de Anomalia')\n",
        "    plt.title('Compara√ß√£o dos Scores')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/plant_disease/analise_limiar.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ESTAT√çSTICAS:\")\n",
        "    print(f\"  Saud√°veis: m√©dia={media_saudavel:.0f}, std={std_saudavel:.0f}\")\n",
        "    print(f\"  Doentes:   m√©dia={media_doente:.0f}, std={std_doente:.0f}\")\n",
        "    print(f\"\\n‚úì LIMIAR RECOMENDADO: {limiar_recomendado:.0f}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return limiar_recomendado\n",
        "\n",
        "# Encontrar limiar ideal\n",
        "limiar_otimo = encontrar_limiar_otimo(\n",
        "    gerador,\n",
        "    pasta_saudaveis='/content/drive/MyDrive/plant_disease/test/healthy',\n",
        "    pasta_doentes='/content/drive/MyDrive/plant_disease/test/diseased'\n",
        ")"
      ],
      "metadata": {
        "id": "OqtrGsnFGEgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processar_lote_completo(gerador, dados, limiar=121462):\n",
        "    \"\"\"\n",
        "    Processa todas as imagens de teste e gera relat√≥rio.\n",
        "\n",
        "    Args:\n",
        "        gerador: Modelo treinado\n",
        "        dados: Dict retornado pela fun√ß√£o verificar_dataset\n",
        "        limiar: Valor de limiar para classifica√ß√£o\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com resultados\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    resultados = []\n",
        "\n",
        "    # Criar pasta para salvar resultados\n",
        "    pasta_resultados = '/content/drive/MyDrive/plant_disease/resultados'\n",
        "    os.makedirs(pasta_resultados, exist_ok=True)\n",
        "    os.makedirs(f'{pasta_resultados}/healthy', exist_ok=True)\n",
        "    os.makedirs(f'{pasta_resultados}/diseased', exist_ok=True)\n",
        "\n",
        "    print(\"üî¨ PROCESSANDO IMAGENS DE TESTE\\n\")\n",
        "\n",
        "    # Processar imagens saud√°veis\n",
        "    print(\"üìó Processando folhas saud√°veis...\")\n",
        "    for img_path in tqdm(dados['test_healthy']):\n",
        "        resultado = diagnosticar_folha(str(img_path), gerador, limiar)\n",
        "\n",
        "        resultados.append({\n",
        "            'arquivo': resultado['arquivo'],\n",
        "            'tipo_real': 'SAUD√ÅVEL',\n",
        "            'diagnostico': resultado['diagnostico'],\n",
        "            'score': resultado['score_anomalia'],\n",
        "            'confianca': resultado['confianca'],\n",
        "            'correto': resultado['diagnostico'] == 'SAUD√ÅVEL'\n",
        "        })\n",
        "\n",
        "        # Salvar visualiza√ß√£o\n",
        "        visualizar_indice_cores(\n",
        "            resultado,\n",
        "            salvar=True,\n",
        "            caminho_saida=f\"{pasta_resultados}/healthy/{resultado['arquivo'].replace('.jpg', '_analise.png')}\"\n",
        "        )\n",
        "        plt.close()\n",
        "\n",
        "    # Processar imagens doentes\n",
        "    print(\"\\nüìï Processando folhas doentes...\")\n",
        "    for img_path in tqdm(dados['test_diseased']):\n",
        "        resultado = diagnosticar_folha(str(img_path), gerador, limiar)\n",
        "\n",
        "        resultados.append({\n",
        "            'arquivo': resultado['arquivo'],\n",
        "            'tipo_real': 'DOENTE',\n",
        "            'diagnostico': resultado['diagnostico'],\n",
        "            'score': resultado['score_anomalia'],\n",
        "            'confianca': resultado['confianca'],\n",
        "            'correto': resultado['diagnostico'] == 'DOENTE'\n",
        "        })\n",
        "\n",
        "        # Salvar visualiza√ß√£o\n",
        "        visualizar_indice_cores(\n",
        "            resultado,\n",
        "            salvar=True,\n",
        "            caminho_saida=f\"{pasta_resultados}/diseased/{resultado['arquivo'].replace('.jpg', '_analise.png')}\"\n",
        "        )\n",
        "        plt.close()\n",
        "\n",
        "    # Criar DataFrame\n",
        "    df = pd.DataFrame(resultados)\n",
        "\n",
        "    # Calcular m√©tricas\n",
        "    acuracia = (df['correto'].sum() / len(df)) * 100\n",
        "\n",
        "    precisao_doente = (df[(df['diagnostico'] == 'DOENTE') & (df['correto'] == True)].shape[0] /\n",
        "                       df[df['diagnostico'] == 'DOENTE'].shape[0] * 100) if df[df['diagnostico'] == 'DOENTE'].shape[0] > 0 else 0\n",
        "\n",
        "    recall_doente = (df[(df['tipo_real'] == 'DOENTE') & (df['correto'] == True)].shape[0] /\n",
        "                     df[df['tipo_real'] == 'DOENTE'].shape[0] * 100)\n",
        "\n",
        "    # Salvar CSV\n",
        "    df.to_csv(f'{pasta_resultados}/resultados_completos.csv', index=False)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"RESULTADOS FINAIS:\")\n",
        "    print(f\"  Total de imagens: {len(df)}\")\n",
        "    print(f\"  Acur√°cia: {acuracia:.2f}%\")\n",
        "    print(f\"  Precis√£o (doentes): {precisao_doente:.2f}%\")\n",
        "    print(f\"  Recall (doentes): {recall_doente:.2f}%\")\n",
        "    print(f\"\\n‚úì Resultados salvos em: {pasta_resultados}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Processar tudo\n",
        "df_resultados = processar_lote_completo(gerador, dados, limiar_otimo)\n",
        "\n",
        "# Visualizar matriz de confus√£o\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(df_resultados['tipo_real'], df_resultados['diagnostico'],\n",
        "                      labels=['SAUD√ÅVEL', 'DOENTE'])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['SAUD√ÅVEL', 'DOENTE'],\n",
        "            yticklabels=['SAUD√ÅVEL', 'DOENTE'])\n",
        "plt.ylabel('Tipo Real')\n",
        "plt.xlabel('Diagn√≥stico')\n",
        "plt.title('Matriz de Confus√£o', fontsize=14, fontweight='bold')\n",
        "plt.savefig('/content/drive/MyDrive/plant_disease/matriz_confusao.png', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "--oDLdDKG9r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processar_lote_completo(gerador, dados, limiar):\n",
        "    \"\"\"\n",
        "    Processa todas as imagens de teste e gera relat√≥rio.\n",
        "\n",
        "    Args:\n",
        "        gerador: Modelo treinado\n",
        "        dados: Dict retornado pela fun√ß√£o verificar_dataset\n",
        "        limiar: Valor de limiar para classifica√ß√£o\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com resultados\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    resultados = []\n",
        "\n",
        "    # Criar pasta para salvar resultados\n",
        "    pasta_resultados = '/content/drive/MyDrive/plant_disease/resultados'\n",
        "    os.makedirs(pasta_resultados, exist_ok=True)\n",
        "    os.makedirs(f'{pasta_resultados}/healthy', exist_ok=True)\n",
        "    os.makedirs(f'{pasta_resultados}/diseased', exist_ok=True)\n",
        "\n",
        "    print(\"üî¨ PROCESSANDO IMAGENS DE TESTE\\n\")\n",
        "\n",
        "    # Processar imagens saud√°veis\n",
        "    print(\"üìó Processando folhas saud√°veis...\")\n",
        "    for img_path in tqdm(dados['test_healthy']):\n",
        "        resultado = diagnosticar_folha(str(img_path), gerador, limiar)\n",
        "\n",
        "        resultados.append({\n",
        "            'arquivo': resultado['arquivo'],\n",
        "            'tipo_real': 'SAUD√ÅVEL',\n",
        "            'diagnostico': resultado['diagnostico'],\n",
        "            'score': resultado['score_anomalia'],\n",
        "            'confianca': resultado['confianca'],\n",
        "            'correto': resultado['diagnostico'] == 'SAUD√ÅVEL'\n",
        "        })\n",
        "\n",
        "        # Salvar visualiza√ß√£o\n",
        "        visualizar_indice_cores(\n",
        "            resultado,\n",
        "            salvar=True,\n",
        "            caminho_saida=f\"{pasta_resultados}/healthy/{resultado['arquivo'].replace('.jpg', '_analise.png')}\"\n",
        "        )\n",
        "        plt.close()\n",
        "\n",
        "    # Processar imagens doentes\n",
        "    print(\"\\nüìï Processando folhas doentes...\")\n",
        "    for img_path in tqdm(dados['test_diseased']):\n",
        "        resultado = diagnosticar_folha(str(img_path), gerador, limiar)\n",
        "\n",
        "        resultados.append({\n",
        "            'arquivo': resultado['arquivo'],\n",
        "            'tipo_real': 'DOENTE',\n",
        "            'diagnostico': resultado['diagnostico'],\n",
        "            'score': resultado['score_anomalia'],\n",
        "            'confianca': resultado['confianca'],\n",
        "            'correto': resultado['diagnostico'] == 'DOENTE'\n",
        "        })\n",
        "\n",
        "        # Salvar visualiza√ß√£o\n",
        "        visualizar_indice_cores(\n",
        "            resultado,\n",
        "            salvar=True,\n",
        "            caminho_saida=f\"{pasta_resultados}/diseased/{resultado['arquivo'].replace('.jpg', '_analise.png')}\"\n",
        "        )\n",
        "        plt.close()\n",
        "\n",
        "    # Criar DataFrame\n",
        "    df = pd.DataFrame(resultados)\n",
        "\n",
        "    # Calcular m√©tricas\n",
        "    acuracia = (df['correto'].sum() / len(df)) * 100\n",
        "\n",
        "    precisao_doente = (df[(df['diagnostico'] == 'DOENTE') & (df['correto'] == True)].shape[0] /\n",
        "                       df[df['diagnostico'] == 'DOENTE'].shape[0] * 100) if df[df['diagnostico'] == 'DOENTE'].shape[0] > 0 else 0\n",
        "\n",
        "    recall_doente = (df[(df['tipo_real'] == 'DOENTE') & (df['correto'] == True)].shape[0] /\n",
        "                     df[df['tipo_real'] == 'DOENTE'].shape[0] * 100)\n",
        "\n",
        "    # Salvar CSV\n",
        "    df.to_csv(f'{pasta_resultados}/resultados_completos.csv', index=False)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"RESULTADOS FINAIS:\")\n",
        "    print(f\"  Total de imagens: {len(df)}\")\n",
        "    print(f\"  Acur√°cia: {acuracia:.2f}%\")\n",
        "    print(f\"  Precis√£o (doentes): {precisao_doente:.2f}%\")\n",
        "    print(f\"  Recall (doentes): {recall_doente:.2f}%\")\n",
        "    print(f\"\\n‚úì Resultados salvos em: {pasta_resultados}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Processar tudo\n",
        "df_resultados = processar_lote_completo(gerador, dados, limiar_otimo)\n",
        "\n",
        "# Visualizar matriz de confus√£o\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(df_resultados['tipo_real'], df_resultados['diagnostico'],\n",
        "                      labels=['SAUD√ÅVEL', 'DOENTE'])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['SAUD√ÅVEL', 'DOENTE'],\n",
        "            yticklabels=['SAUD√ÅVEL', 'DOENTE'])\n",
        "plt.ylabel('Tipo Real')\n",
        "plt.xlabel('Diagn√≥stico')\n",
        "plt.title('Matriz de Confus√£o', fontsize=14, fontweight='bold')\n",
        "plt.savefig('/content/drive/MyDrive/plant_disease/matriz_confusao.png', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vJZJ45rCJVEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f859a38a"
      },
      "source": [
        "# Task\n",
        "Implement Grad-CAM by defining functions to register forward and backward hooks on the Generator model, enabling extraction of feature maps and gradients from the last convolutional layer. Then, apply these to calculate Grad-CAM heatmaps for image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e982213f"
      },
      "source": [
        "## Implementar Grad-CAM\n",
        "\n",
        "### Subtask:\n",
        "Implementar as fun√ß√µes necess√°rias para calcular o Grad-CAM no modelo Gerador. Isso envolve registrar hooks para extrair mapas de caracter√≠sticas e gradientes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f281232"
      },
      "source": [
        "## Implementando Grad-CAM para An√°lise de Anomalias\n",
        "\n",
        "Para entender **onde** o modelo Gerador detecta anomalias nas folhas (ou seja, onde ele tem dificuldade em reconstruir a cor original), vamos implementar o **Grad-CAM (Gradient-weighted Class Activation Mapping)**. Embora o Grad-CAM seja tipicamente usado para modelos de classifica√ß√£o, podemos adapt√°-lo para nosso cen√°rio de detec√ß√£o de anomalias.\n",
        "\n",
        "**Como funciona no nosso contexto:**\n",
        "1.  O modelo Gerador recebe uma imagem em escala de cinza e tenta coloriz√°-la (produzir a imagem 'saud√°vel' reconstru√≠da).\n",
        "2.  Uma 'anomalia' √© detectada quando a imagem reconstru√≠da √© significativamente diferente da imagem original colorida. A m√©trica `CIEDE2000` quantifica essa diferen√ßa.\n",
        "3.  Para o Grad-CAM, precisamos de um 'score' ou 'loss' para retropropagar. Em nosso caso, podemos usar a `Loss L1` (ou a `Loss GAN` do gerador) em rela√ß√£o √† imagem colorida real como o 'alvo' para a retropropaga√ß√£o.\n",
        "4.  O Grad-CAM nos mostrar√° quais partes da camada de caracter√≠sticas final do Gerador foram mais ativadas para produzir a diferen√ßa na reconstru√ß√£o (ou seja, onde a Loss L1 foi maior).\n",
        "\n",
        "Vamos focar em uma camada espec√≠fica do decoder do Gerador, pois √© l√° que as informa√ß√µes visuais de alto n√≠vel s√£o combinadas para reconstruir a imagem. O objetivo √© visualizar as regi√µes que mais contribu√≠ram para a 'dificuldade' de coloriza√ß√£o do Gerador, indicando √°reas an√¥malas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81389ab0"
      },
      "source": [
        "**Reasoning**:\n",
        "Now, I will implement the `GradCAM` class as described in the instructions, setting up forward and backward hooks to capture feature maps and gradients from a specified layer of the generator model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "etAMngA9Ej99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e925e356"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class GradCAM:\n",
        "    \"\"\"\n",
        "    Implementa Grad-CAM para visualizar as regi√µes mais ativas no Gerador.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.feature_maps = None\n",
        "        self.gradients = None\n",
        "\n",
        "        # Registrar hooks\n",
        "        self.target_layer.register_forward_hook(self._save_feature_maps_hook)\n",
        "        self.target_layer.register_full_backward_hook(self._save_gradients_hook)\n",
        "\n",
        "    def _save_feature_maps_hook(self, module, input, output):\n",
        "        self.feature_maps = output\n",
        "\n",
        "    def _save_gradients_hook(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0]\n",
        "\n",
        "    def generate_heatmap(self, input_tensor, target_output):\n",
        "        self.model.eval()\n",
        "        # Limpar gradientes anteriores\n",
        "        if self.feature_maps is not None:\n",
        "            self.feature_maps.retain_grad()\n",
        "\n",
        "        # Realizar forward pass\n",
        "        output = self.model(input_tensor)\n",
        "\n",
        "        # Zero os gradientes do modelo antes do backward pass\n",
        "        self.model.zero_grad()\n",
        "\n",
        "        # Calcular a loss em rela√ß√£o ao 'alvo' para o backward pass\n",
        "        # Usamos L1 Loss entre a sa√≠da do gerador e a imagem colorida real\n",
        "        loss = F.l1_loss(output, target_output) # target_output aqui seria a imagem colorida original\n",
        "        loss.backward()\n",
        "\n",
        "        # Extrair feature maps e gradients capturados pelos hooks\n",
        "        feature_maps = self.feature_maps.cpu().data.numpy()[0]\n",
        "        gradients = self.gradients.cpu().data.numpy()[0]\n",
        "\n",
        "        # Pooling global dos gradientes (m√©dia)\n",
        "        pooled_gradients = np.mean(gradients, axis=(1, 2))\n",
        "\n",
        "        # Ponderar os feature maps pelos gradientes m√©dios\n",
        "        for i, w in enumerate(pooled_gradients):\n",
        "            feature_maps[i, :, :] = w * feature_maps[i, :, :]\n",
        "\n",
        "        # Criar o heatmap\n",
        "        heatmap = np.sum(feature_maps, axis=0)\n",
        "        heatmap = np.maximum(heatmap, 0) # Aplicar ReLU\n",
        "\n",
        "        # Normalizar heatmap\n",
        "        if np.max(heatmap) > 0:\n",
        "            heatmap /= np.max(heatmap)\n",
        "\n",
        "        # Redimensionar para o tamanho da imagem original (256x256)\n",
        "        heatmap = F.interpolate(\n",
        "            torch.from_numpy(heatmap).unsqueeze(0).unsqueeze(0),\n",
        "            size=(input_tensor.shape[2], input_tensor.shape[3]),\n",
        "            mode='bilinear',\n",
        "            align_corners=False\n",
        "        ).squeeze().numpy()\n",
        "\n",
        "        return heatmap\n",
        "\n",
        "print(\"‚úì Classe GradCAM implementada com sucesso.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1306a4d"
      },
      "source": [
        "## Aplicar Grad-CAM em Imagens de Teste\n",
        "\n",
        "### Subtask:\n",
        "Selecionar imagens de teste (saud√°veis e doentes) e aplicar a l√≥gica do Grad-CAM para gerar mapas de calor que destacam as regi√µes mais importantes para o diagn√≥stico do modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4639657"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will choose a target layer within the generator model for Grad-CAM. Then, I will instantiate the GradCAM class with the generator and the selected layer. After that, I will select one healthy and one diseased image from the test datasets. Finally, for each selected image, I will prepare the input tensors, generate the Grad-CAM heatmap, and store all necessary outputs for subsequent visualization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Criar pasta para salvar resultados do Grad-CAM\n",
        "pasta_gradcam_results = '/content/drive/MyDrive/plant_disease/gradcam_results/'\n",
        "os.makedirs(pasta_gradcam_results, exist_ok=True)\n",
        "print(f\"‚úì Pasta de resultados Grad-CAM criada em: {pasta_gradcam_results}\")\n",
        "\n",
        "for img_type, result in gradcam_results.items():\n",
        "    original_img = result['original_img']\n",
        "    generated_img = result['generated_img']\n",
        "    heatmap = result['heatmap']\n",
        "    filename = result['filename']\n",
        "\n",
        "    # Redimensionar heatmap para o tamanho da imagem original (j√° feito no generate_heatmap, mas garantindo)\n",
        "    # heatmap_resized = np.array(Image.fromarray((heatmap * 255).astype(np.uint8)).resize(original_img.shape[1::-1], Image.BILINEAR)) / 255.0\n",
        "    # A linha acima n√£o √© necess√°ria porque o heatmap j√° foi interpolado para o tamanho correto dentro de generate_heatmap\n",
        "    heatmap_resized = heatmap # Usamos o heatmap j√° redimensionado\n",
        "\n",
        "    # Criar a sobreposi√ß√£o\n",
        "    overlay = original_img.copy()\n",
        "    # Convert original_img to 3 channels if it's not already, for consistent overlaying\n",
        "    if len(overlay.shape) == 2:\n",
        "        overlay = np.stack([overlay, overlay, overlay], axis=-1)\n",
        "\n",
        "    # Aplicar o heatmap como uma m√°scara de calor no canal vermelho, ou como alpha\n",
        "    # Usando plt.imshow para a sobreposi√ß√£o para melhor controle de cmap e alpha\n",
        "\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
        "    fig.suptitle(f'Grad-CAM An√°lise - {img_type.upper()} ({filename})', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Imagem Original\n",
        "    axes[0].imshow(original_img)\n",
        "    axes[0].set_title('Imagem Original')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # 2. Imagem Gerada pelo Modelo\n",
        "    axes[1].imshow(generated_img)\n",
        "    axes[1].set_title('Imagem Gerada (Reconstru√≠da)')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # 3. Grad-CAM Heatmap\n",
        "    im = axes[2].imshow(heatmap_resized, cmap='jet', alpha=0.7)\n",
        "    axes[2].set_title('Grad-CAM Heatmap')\n",
        "    axes[2].axis('off')\n",
        "    plt.colorbar(im, ax=axes[2], fraction=0.046, pad=0.04)\n",
        "\n",
        "    # 4. Sobreposi√ß√£o do Heatmap na Imagem Original\n",
        "    axes[3].imshow(original_img)\n",
        "    axes[3].imshow(heatmap_resized, cmap='jet', alpha=0.5) # Alpha para visualiza√ß√£o da imagem subjacente\n",
        "    axes[3].set_title('Heatmap sobre Original')\n",
        "    axes[3].axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Ajustar layout para n√£o sobrepor o t√≠tulo principal\n",
        "\n",
        "    # Salvar a figura\n",
        "    save_path = os.path.join(pasta_gradcam_results, f'gradcam_{img_type}_{filename.replace(\".jpg\", \".png\").replace(\".jpeg\", \".png\")}')\n",
        "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
        "    print(f\"‚úì Gr√°fico Grad-CAM salvo em: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"‚úì Visualiza√ß√£o dos resultados Grad-CAM conclu√≠da.\")"
      ],
      "metadata": {
        "id": "vWN7cgIvGO5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# 1. Escolher uma camada convolucional adequada do modelo gerador\n",
        "# A instru√ß√£o sugere 'gerador.up7.model[0]' ou 'gerador.down8.model[0]'.\n",
        "# Vamos usar a primeira camada convolucional do bloco 'up7' do gerador.\n",
        "target_layer = gerador.up7.model[0] # Ou gerador.down8.model[0] se preferir uma camada do encoder\n",
        "\n",
        "# 2. Crie uma inst√¢ncia da classe GradCAM\n",
        "grad_cam_instance = GradCAM(gerador, target_layer)\n",
        "print(f\"‚úì Inst√¢ncia GradCAM criada com camada alvo: {target_layer}\")\n",
        "\n",
        "# 3. Selecionar uma imagem de folha saud√°vel e uma imagem de folha doente\n",
        "# Usando os dados j√° carregados de `dados`\n",
        "healthy_img_path = dados['test_healthy'][0] # Primeira imagem saud√°vel\n",
        "diseased_img_path = dados['test_diseased'][0] # Primeira imagem doente\n",
        "\n",
        "print(f\"\\nImagens selecionadas:\\n  Saud√°vel: {healthy_img_path.name}\\n  Doente:   {diseased_img_path.name}\")\n",
        "\n",
        "# Prepare transforms for input and target\n",
        "# For input_tensor (grayscale) - this is what the generator takes\n",
        "transform_gray_input = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# For target_output (original color) - this is for L1 loss calculation in GradCAM\n",
        "transform_color_target = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Armazenar resultados para visualiza√ß√£o posterior\n",
        "gradcam_results = {}\n",
        "\n",
        "for img_type, path in [('healthy', healthy_img_path), ('diseased', diseased_img_path)]:\n",
        "    print(f\"\\nProcessando imagem {img_type}: {path.name}\")\n",
        "\n",
        "    # a. Carregue a imagem original e redimensione-a para 256x256 pixels.\n",
        "    original_img_pil = Image.open(path).convert('RGB')\n",
        "    original_img_numpy = np.array(original_img_pil.resize((256, 256))) / 255.0 # Normalizado para [0,1] para exibi√ß√£o\n",
        "\n",
        "    # b. Converta a imagem original para escala de cinza e aplique as transforma√ß√µes\n",
        "    img_gray_pil = original_img_pil.convert('L')\n",
        "    input_tensor = transform_gray_input(img_gray_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    # c. Aplique as transforma√ß√µes na imagem colorida original para criar o target_output\n",
        "    target_output_tensor = transform_color_target(original_img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    # d. Gere o mapa de calor do Grad-CAM\n",
        "    heatmap = grad_cam_instance.generate_heatmap(input_tensor, target_output_tensor)\n",
        "\n",
        "    # Gerar a imagem colorida pelo gerador (sa√≠da do gerador para input_tensor)\n",
        "    gerador.eval()\n",
        "    with torch.no_grad():\n",
        "        generated_img_tensor = gerador(input_tensor)\n",
        "    generated_img_numpy = generated_img_tensor.squeeze().cpu().numpy()\n",
        "    generated_img_numpy = np.transpose(generated_img_numpy, (1, 2, 0))\n",
        "    generated_img_numpy = (generated_img_numpy + 1) / 2 # Desnormalizar [-1,1] -> [0,1]\n",
        "    generated_img_numpy = np.clip(generated_img_numpy, 0, 1)\n",
        "\n",
        "    # e. Armazene a imagem original, a imagem de entrada em escala de cinza, a imagem reconstru√≠da e o mapa de calor\n",
        "    gradcam_results[img_type] = {\n",
        "        'original_img': original_img_numpy,\n",
        "        'gray_input_img': np.array(img_gray_pil.resize((256,256))) / 255.0,\n",
        "        'generated_img': generated_img_numpy,\n",
        "        'heatmap': heatmap,\n",
        "        'filename': path.name\n",
        "    }\n",
        "\n",
        "print(\"‚úì Resultados do Grad-CAM calculados e armazenados para as imagens selecionadas.\")"
      ],
      "metadata": {
        "id": "N5jyqXadFf06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0600aa8b"
      },
      "source": [
        "**Reasoning**:\n",
        "The error `RuntimeError: can't retain_grad on Tensor that has requires_grad=False` indicates that `retain_grad()` was called on a tensor (`self.feature_maps`) that does not track gradients. I need to ensure that the feature maps obtained from the forward hook have `requires_grad=True` so that gradients can be computed and retained for them during the backward pass. I will modify the `_save_feature_maps_hook` to set `requires_grad_()` on the output tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4fb95e1"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class GradCAM:\n",
        "    \"\"\"\n",
        "    Implementa Grad-CAM para visualizar as regi√µes mais ativas no Gerador.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.feature_maps = None\n",
        "        self.gradients = None\n",
        "\n",
        "        # Registrar hooks\n",
        "        self.target_layer.register_forward_hook(self._save_feature_maps_hook)\n",
        "        self.target_layer.register_full_backward_hook(self._save_gradients_hook)\n",
        "\n",
        "    def _save_feature_maps_hook(self, module, input, output):\n",
        "        # Ensure feature_maps require gradients to call .retain_grad() later\n",
        "        output.requires_grad_(True)\n",
        "        self.feature_maps = output\n",
        "\n",
        "    def _save_gradients_hook(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0]\n",
        "\n",
        "    def generate_heatmap(self, input_tensor, target_output):\n",
        "        self.model.eval()\n",
        "\n",
        "        # Realizar forward pass\n",
        "        output = self.model(input_tensor)\n",
        "\n",
        "        # Zero os gradientes do modelo antes do backward pass\n",
        "        self.model.zero_grad()\n",
        "\n",
        "        # Calcular a loss em rela√ß√£o ao 'alvo' para o backward pass\n",
        "        # Usamos L1 Loss entre a sa√≠da do gerador e a imagem colorida real\n",
        "        loss = F.l1_loss(output, target_output) # target_output aqui seria a imagem colorida original\n",
        "        loss.backward()\n",
        "\n",
        "        # Extrair feature maps e gradients capturados pelos hooks\n",
        "        feature_maps = self.feature_maps.cpu().data.numpy()[0]\n",
        "        gradients = self.gradients.cpu().data.numpy()[0]\n",
        "\n",
        "        # Pooling global dos gradientes (m√©dia)\n",
        "        pooled_gradients = np.mean(gradients, axis=(1, 2))\n",
        "\n",
        "        # Ponderar os feature maps pelos gradientes m√©dios\n",
        "        for i, w in enumerate(pooled_gradients):\n",
        "            feature_maps[i, :, :] = w * feature_maps[i, :, :]\n",
        "\n",
        "        # Criar o heatmap\n",
        "        heatmap = np.sum(feature_maps, axis=0)\n",
        "        heatmap = np.maximum(heatmap, 0) # Aplicar ReLU\n",
        "\n",
        "        # Normalizar heatmap\n",
        "        if np.max(heatmap) > 0:\n",
        "            heatmap /= np.max(heatmap)\n",
        "\n",
        "        # Redimensionar para o tamanho da imagem original (256x256)\n",
        "        heatmap = F.interpolate(\n",
        "            torch.from_numpy(heatmap).unsqueeze(0).unsqueeze(0),\n",
        "            size=(input_tensor.shape[2], input_tensor.shape[3]),\n",
        "            mode='bilinear',\n",
        "            align_corners=False\n",
        "        ).squeeze().numpy()\n",
        "\n",
        "        return heatmap\n",
        "\n",
        "print(\"‚úì Classe GradCAM implementada com sucesso.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54b30796"
      },
      "source": [
        "**Reasoning**:\n",
        "The `GradCAM` class has been updated to correctly handle gradient retention. I will now re-run the previous code block to apply the corrected Grad-CAM implementation to the selected healthy and diseased test images, generate their heatmaps, and store the results for visualization as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bea642f2"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# 1. Escolher uma camada convolucional adequada do modelo gerador\n",
        "# A instru√ß√£o sugere 'gerador.up7.model[0]' ou 'gerador.down8.model[0]'.\n",
        "# Vamos usar a primeira camada convolucional do bloco 'up7' do gerador.\n",
        "target_layer = gerador.up7.model[0] # Ou gerador.down8.model[0] se preferir uma camada do encoder\n",
        "\n",
        "# 2. Crie uma inst√¢ncia da classe GradCAM\n",
        "grad_cam_instance = GradCAM(gerador, target_layer)\n",
        "print(f\"‚úì Inst√¢ncia GradCAM criada com camada alvo: {target_layer}\")\n",
        "\n",
        "# 3. Selecionar uma imagem de folha saud√°vel e uma imagem de folha doente\n",
        "# Usando os dados j√° carregados de `dados`\n",
        "healthy_img_path = dados['test_healthy'][0] # Primeira imagem saud√°vel\n",
        "diseased_img_path = dados['test_diseased'][0] # Primeira imagem doente\n",
        "\n",
        "print(f\"\\nImagens selecionadas:\\n  Saud√°vel: {healthy_img_path.name}\\n  Doente:   {diseased_img_path.name}\")\n",
        "\n",
        "# Prepare transforms for input and target\n",
        "# For input_tensor (grayscale) - this is what the generator takes\n",
        "transform_gray_input = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# For target_output (original color) - this is for L1 loss calculation in GradCAM\n",
        "transform_color_target = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Armazenar resultados para visualiza√ß√£o posterior\n",
        "gradcam_results = {}\n",
        "\n",
        "for img_type, path in [('healthy', healthy_img_path), ('diseased', diseased_img_path)]:\n",
        "    print(f\"\\nProcessando imagem {img_type}: {path.name}\")\n",
        "\n",
        "    # a. Carregue a imagem original e redimensione-a para 256x256 pixels.\n",
        "    original_img_pil = Image.open(path).convert('RGB')\n",
        "    original_img_numpy = np.array(original_img_pil.resize((256, 256))) / 255.0 # Normalizado para [0,1] para exibi√ß√£o\n",
        "\n",
        "    # b. Converta a imagem original para escala de cinza e aplique as transforma√ß√µes\n",
        "    img_gray_pil = original_img_pil.convert('L')\n",
        "    input_tensor = transform_gray_input(img_gray_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    # c. Aplique as transforma√ß√µes na imagem colorida original para criar o target_output\n",
        "    target_output_tensor = transform_color_target(original_img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    # d. Gere o mapa de calor do Grad-CAM\n",
        "    heatmap = grad_cam_instance.generate_heatmap(input_tensor, target_output_tensor)\n",
        "\n",
        "    # Gerar a imagem colorida pelo gerador (sa√≠da do gerador para input_tensor)\n",
        "    gerador.eval()\n",
        "    with torch.no_grad():\n",
        "        generated_img_tensor = gerador(input_tensor)\n",
        "    generated_img_numpy = generated_img_tensor.squeeze().cpu().numpy()\n",
        "    generated_img_numpy = np.transpose(generated_img_numpy, (1, 2, 0))\n",
        "    generated_img_numpy = (generated_img_numpy + 1) / 2 # Desnormalizar [-1,1] -> [0,1]\n",
        "    generated_img_numpy = np.clip(generated_img_numpy, 0, 1)\n",
        "\n",
        "    # e. Armazene a imagem original, a imagem de entrada em escala de cinza, a imagem reconstru√≠da e o mapa de calor\n",
        "    gradcam_results[img_type] = {\n",
        "        'original_img': original_img_numpy,\n",
        "        'gray_input_img': np.array(img_gray_pil.resize((256,256))) / 255.0,\n",
        "        'generated_img': generated_img_numpy,\n",
        "        'heatmap': heatmap,\n",
        "        'filename': path.name\n",
        "    }\n",
        "\n",
        "print(\"‚úì Resultados do Grad-CAM calculados e armazenados para as imagens selecionadas.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "def736bf"
      },
      "source": [
        "## Visualizar Resultados do Grad-CAM\n",
        "\n",
        "### Subtask:\n",
        "Plotar as imagens originais, os mapas de calor do Grad-CAM e a sobreposi√ß√£o desses mapas nas imagens originais para uma an√°lise visual das regi√µes de anomalia.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "537813a5"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to import `matplotlib.pyplot` and `seaborn` for plotting. Although `seaborn` is not explicitly used for plotting in the instructions, it's good practice to import it alongside `matplotlib` for enhanced aesthetics if needed later. Then, I will iterate through the `gradcam_results` to generate and display visualizations for each image type as specified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d73b2404"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Criar pasta para salvar resultados do Grad-CAM\n",
        "pasta_gradcam_results = '/content/drive/MyDrive/plant_disease/gradcam_results/'\n",
        "os.makedirs(pasta_gradcam_results, exist_ok=True)\n",
        "print(f\"‚úì Pasta de resultados Grad-CAM criada em: {pasta_gradcam_results}\")\n",
        "\n",
        "for img_type, result in gradcam_results.items():\n",
        "    original_img = result['original_img']\n",
        "    generated_img = result['generated_img']\n",
        "    heatmap = result['heatmap']\n",
        "    filename = result['filename']\n",
        "\n",
        "    # Redimensionar heatmap para o tamanho da imagem original (j√° feito no generate_heatmap, mas garantindo)\n",
        "    # heatmap_resized = np.array(Image.fromarray((heatmap * 255).astype(np.uint8)).resize(original_img.shape[1::-1], Image.BILINEAR)) / 255.0\n",
        "    # A linha acima n√£o √© necess√°ria porque o heatmap j√° foi interpolado para o tamanho correto dentro de generate_heatmap\n",
        "    heatmap_resized = heatmap # Usamos o heatmap j√° redimensionado\n",
        "\n",
        "    # Criar a sobreposi√ß√£o\n",
        "    overlay = original_img.copy()\n",
        "    # Convert original_img to 3 channels if it's not already, for consistent overlaying\n",
        "    if len(overlay.shape) == 2:\n",
        "        overlay = np.stack([overlay, overlay, overlay], axis=-1)\n",
        "\n",
        "    # Aplicar o heatmap como uma m√°scara de calor no canal vermelho, ou como alpha\n",
        "    # Usando plt.imshow para a sobreposi√ß√£o para melhor controle de cmap e alpha\n",
        "\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
        "    fig.suptitle(f'Grad-CAM An√°lise - {img_type.upper()} ({filename})', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Imagem Original\n",
        "    axes[0].imshow(original_img)\n",
        "    axes[0].set_title('Imagem Original')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # 2. Imagem Gerada pelo Modelo\n",
        "    axes[1].imshow(generated_img)\n",
        "    axes[1].set_title('Imagem Gerada (Reconstru√≠da)')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # 3. Grad-CAM Heatmap\n",
        "    im = axes[2].imshow(heatmap_resized, cmap='jet', alpha=0.7)\n",
        "    axes[2].set_title('Grad-CAM Heatmap')\n",
        "    axes[2].axis('off')\n",
        "    plt.colorbar(im, ax=axes[2], fraction=0.046, pad=0.04)\n",
        "\n",
        "    # 4. Sobreposi√ß√£o do Heatmap na Imagem Original\n",
        "    axes[3].imshow(original_img)\n",
        "    axes[3].imshow(heatmap_resized, cmap='jet', alpha=0.5) # Alpha para visualiza√ß√£o da imagem subjacente\n",
        "    axes[3].set_title('Heatmap sobre Original')\n",
        "    axes[3].axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Ajustar layout para n√£o sobrepor o t√≠tulo principal\n",
        "\n",
        "    # Salvar a figura\n",
        "    save_path = os.path.join(pasta_gradcam_results, f'gradcam_{img_type}_{filename.replace(\".jpg\", \".png\").replace(\".jpeg\", \".png\")}')\n",
        "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
        "    print(f\"‚úì Gr√°fico Grad-CAM salvo em: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"‚úì Visualiza√ß√£o dos resultados Grad-CAM conclu√≠da.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0514aef9"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Discutir as informa√ß√µes adicionais que o Grad-CAM fornece para a compreens√£o do diagn√≥stico e como ele pode ser usado para interpretar as decis√µes do modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3caa958b"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "Grad-CAM provides visual information about which regions of an input image are most influential in the model's decision-making process. In the context of anomaly detection using a Generator model, Grad-CAM highlights areas within the image that the Generator found most challenging to reconstruct, specifically by identifying where the L1 loss (difference between the generated and original image) was highest. This allows for interpreting the model's decisions by visually pinpointing potential anomalous regions.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   A `GradCAM` class was successfully implemented, equipped with forward and backward hooks to capture feature maps and gradients from a specified target convolutional layer (`gerador.up7.model[0]`) of the Generator model.\n",
        "*   During the application of Grad-CAM, an initial `RuntimeError` occurred due to the `feature_maps` tensor not having `requires_grad=True`. This was corrected by explicitly setting `output.requires_grad_(True)` within the `_save_feature_maps_hook` method.\n",
        "*   Post-correction, Grad-CAM heatmaps were successfully generated for both a healthy (`leaf a21-a23 ad_1.png`) and a diseased (`a1001-1003 ad_0.png`) leaf image, along with the model's reconstructed outputs.\n",
        "*   Visualization plots were successfully generated and saved, presenting a four-panel view for each image, including: the original image, the model's generated (reconstructed) image, the Grad-CAM heatmap, and the heatmap overlaid on the original image.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Grad-CAM successfully provides a visual explanation of where the generative model \"struggles\" to reconstruct the image, indicating areas of potential anomaly. This can be crucial for localizing plant diseases.\n",
        "*   The generated Grad-CAM heatmaps can be further analyzed by correlating the highlighted regions with expert-annotated disease areas to quantitatively assess the model's ability to localize anomalies.\n"
      ]
    }
  ]
}